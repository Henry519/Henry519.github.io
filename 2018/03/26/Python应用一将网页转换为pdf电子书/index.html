<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge"/>
    
    <title>Python实践一、将网页转换为pdf电子书 | Henry的博客</title>
    <meta name="renderer" content="webkit">
    <meta name="HandheldFriendly" content="True">
    <meta name="MobileOptimized" content="320">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

    <meta name="description" content="ios开发、iOS交流、iOS技术">

    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Python实践一、将网页转换为pdf电子书 | Henry的博客">
    <meta name="twitter:description" content="ios开发、iOS交流、iOS技术">

    <meta property="og:type" content="article">
    <meta property="og:title" content="Python实践一、将网页转换为pdf电子书 | Henry的博客">
    <meta property="og:description" content="ios开发、iOS交流、iOS技术">

    
    <meta name="author" content="Henry">
    
    <link rel="stylesheet" href="/css/vno.css">
    <link rel="stylesheet" href="//netdna.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css">

    

    <meta name="generator" content="hexo"/>
    
    <link rel="alternate" type="application/rss+xml" title="Henry的博客" href="/atom.xml">
    

    <link rel="canonical" href="http://yoursite.com/2018/03/26/Python应用一将网页转换为pdf电子书/"/>

    
      
</head>

<body class="home-template no-js">
    <script src="//cdn.bootcss.com/jquery/2.1.4/jquery.min.js"></script>
    <script src="/js/main.js"></script>
    <span class="mobile btn-mobile-menu">
        <i class="fa fa-list btn-mobile-menu__icon"></i>
        <i class="fa fa-angle-up btn-mobile-close__icon hidden"></i>
    </span>

    
<header class="panel-cover panel-cover--collapsed" style="background-image: url(/images/background-cover-road.jpg)">
  <div class="panel-main">
    <div class="panel-main__inner panel-inverted">
    <div class="panel-main__content">

        <a href="/" title="前往 Henry的博客 的主页"><img src="/images/avatar_dog.jpg" width="80" alt="Henry的博客 logo" class="panel-cover__logo logo" /></a>
        <h1 class="panel-cover__title panel-title"><a href="/" title="link to homepage for Henry的博客">Henry的博客</a></h1>
        
        <span class="panel-cover__subtitle panel-subtitle">有理想的人，生活总是火热的</span>
        
        <hr class="panel-cover__divider" />
        <p class="panel-cover__description">欢迎来到Henry的博客，希望与您在iOS开发领域共同交流与学习</p>
        <hr class="panel-cover__divider panel-cover__divider--secondary" />

        <div class="navigation-wrapper">
          <div>
          <nav class="cover-navigation cover-navigation--primary">
            <ul class="navigation">
              <li class="navigation__item"><a href="/#blog" title="访问博客" class="blog-button">博客</a></li>
            
            </ul>
          </nav>
          </div>
          <div>
          <nav class="cover-navigation navigation--social">
  <ul class="navigation">

  <!-- Weibo-->
  

  <!-- Github -->
  
  <li class="navigation__item">
    <a href="https://github.com/Henry519" title="查看我的GitHub主页" target="_blank">
      <i class='social fa fa-github'></i>
      <span class="label">Github</span>
    </a>
  </li>


<!-- Stack Overflow -->
        

  <!-- Google Plus -->
  

<!-- Facebook -->

  
<!-- Twitter -->

  

  <li class="navigation__item">
    <a href="/atom.xml" title="RSS" target="_blank">
      <i class='social fa fa-rss'></i>
      <span class="label">RSS</span>
    </a>
  </li>



  </ul>
</nav>

          </div>
        </div>

      </div>

    </div>

    <div class="panel-cover--overlay cover-slate"></div>
  </div>
</header>

    <div class="content-wrapper">
        <div class="content-wrapper__inner">
            <article class="post-container post-container--single">

  <header class="post-header">
    <div class="post-meta">
      <time datetime="2018-03-26T06:06:27.000Z" class="post-list__meta--date date">2018-03-26</time> &#8226; <span class="post-meta__tags tags">于&nbsp;
  <a class="tag-link" href="/tags/Python/">Python</a>
 </span>
      <span class="page-pv">
      &nbsp;阅读&nbsp;<span id="busuanzi_value_page_pv"><i class="fa fa-spinner fa-spin"></i></span>
      </span> 
   
    </div>
    <h1 class="post-title">Python实践一、将网页转换为pdf电子书</h1>
  </header>

  <section class="post">
    <p>本人是个”收集狂”(不要想歪了哈，我只是喜欢收藏技术贴)，遇到好的东西就喜欢收藏或记录下来，尤其是好的技术文章或者工具。这里就要提到廖雪峰老师的官方网站了，廖老师写的Python、JavaScript、Git教程真心好呀，每每都要去逛逛。于是就有了今天这个需求，把廖老师的教程由网页转为PDF电子书，这样就可以随时随地离线学习加收藏了。说到这里进入今天的主题<strong>Python爬虫实践：将网页转换为pdf电子书</strong></p>
<p>写爬虫似乎没有比用 Python 更合适了，Python 社区提供的爬虫工具多得让你眼花缭乱，各种拿来就可以直接用的 library 分分钟就可以写出一个爬虫出来，今天就琢磨着写一个爬虫，将廖雪峰的 Python 教程 爬下来做成 PDF 电子书方便离线阅读。</p>
<p>开始写爬虫前，我们先来分析一下该网站的页面结构，网页的左侧是教程的目录大纲，每个 URL 对应到右边的一篇文章，右侧上方是文章的标题，中间是文章的正文部分，正文内容是我们关心的重点，我们要爬的数据就是所有网页的正文部分，下方是用户的评论区，评论区对我们没什么用，所以可以忽略它。</p>
<p><img src="/2018/03/26/Python应用一将网页转换为pdf电子书/01.png" alt=""></p>
<p><strong>工具准备</strong></p>
<p>弄清楚了网站的基本结构后就可以开始准备爬虫所依赖的工具包了。requests、beautifulsoup 是爬虫两大神器，reuqests 用于网络请求，beautifusoup 用于操作 html 数据。有了这两把梭子，干起活来利索，scrapy 这样的爬虫框架我们就不用了，小程序派上它有点杀鸡用牛刀的意思。此外，既然是把 html 文件转为 pdf，那么也要有相应的库支持， wkhtmltopdf 就是一个非常好的工具，它可以用适用于多平台的 html 到 pdf 的转换，pdfkit 是 wkhtmltopdf 的Python封装包。首先安装好下面的依赖包，接着安装 wkhtmltopdf</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">pip install requests</div><div class="line">pip install beautifulsoup4</div><div class="line">pip install pdfkit</div><div class="line">pip install PyPDF2</div></pre></td></tr></table></figure>
<p>安装 wkhtmltopdf</p>
<p>Ubuntu 和 CentOS 可以直接用命令行进行安装。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ sudo apt-get install wkhtmltopdf  # ubuntu</div><div class="line">$ sudo yum intsall wkhtmltopdf      # centos</div></pre></td></tr></table></figure>
<p>Windows平台直接在 wkhtmltopdf 官网2下载稳定版的进行安装，安装完成之后把该程序的执行路径加入到系统环境 $PATH 变量中，否则 pdfkit 找不到 wkhtmltopdf 就出现错误 <code>No wkhtmltopdf executable found</code> <strong>这里就要多说几句了，因为这里处理不好，程序执行<code>pdfkit.from_file(htmls, file_name, options=options)</code>的时候就会报错。</strong></p>
<p>现在开始手动安装wkhtmltopdf（博主电脑操作系统是 macOS 10.12.2）</p>
<p>1、去官网下<strong><a href="https://wkhtmltopdf.org/downloads.html#stable" target="_blank" rel="external">wkhtmltopdf</a></strong>。下载完成运行wkhtmltox-0.12.4_osx-cocoa-x86-64.pkg</p>
<p>2、把wkhtmltoimage和wkhtmltopdf复制到/usr/bin目录，更改所有者，并增加可执行属性</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">sudo cp /usr/local/bin/wkhtmltopdf /usr/bin/</div><div class="line">sudo cp /usr/local/bin/wkhtmltoimage /usr/bin/</div><div class="line">sudo chown root:root /usr/bin/wkhtmltopdf</div><div class="line">sudo chown root:root /usr/bin/wkhtmltoimage</div><div class="line">sudo chmod +x /usr/bin/wkhtmltopdf</div><div class="line">sudo chmod +x /usr/bin/wkhtmltoimage</div></pre></td></tr></table></figure>
<p>不出意外你在执行第一句的时候就会遇到<code>chmod:Unable to change file modle on /usr/bin</code>这是因为苹果从 OS X El Capitan 10.11 系统开始使用了 Rootless 机制，可以将该机制理解为一个更高等级的系统的内核保护措施，系统默认将会锁定 /system、/sbin、/usr 这三个目录。</p>
<p>关闭Rootless</p>
<p>关闭和开启 Rootless 非常简单，方法如下：重启 Mac，听到开机启动声后按下 Command+R，进入恢复模式，在上面的菜单实用工具中找到并打开 Terminal（如果顶部没出现菜单，请继续重启^_^）。输入如下命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">$ csrutil disable #关闭 Rootless</div><div class="line">$ csrutil enable #开启 Rootless</div></pre></td></tr></table></figure>
<p>OK,到此我们工具及环境配置好了，下面开始实现功能。</p>
<p>爬虫实现</p>
<p>一切准备就绪后就可以上代码了，不过写代码之前还是先整理一下思绪。程序的目的是要把所有 URL 对应的 html 正文部分保存到本地，然后利用 pdfkit 把这些文件转换成一个 pdf 文件。我们把任务拆分一下，首先是把某一个 URL 对应的 html 正文保存到本地，然后找到所有的 URL 执行相同的操作。用 Chrome 浏览器找到页面正文部分的标签，按 F12 找到正文对应的 div 标签：<code>&lt;div class=&quot;x-wiki-content&quot;&gt;</code>，该 div 是网页的正文内容。用 requests 把整个页面加载到本地后，就可以使用 beautifulsoup 操作 HTML 的 dom 元素 来提取正文内容了。</p>
<p><img src="/2018/03/26/Python应用一将网页转换为pdf电子书/02.png" alt=""></p>
<p>具体的实现代码如下：用 soup.find_all 函数找到正文标签，然后把正文部分的内容保存到 a.html 文件中。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">def parse_url_to_html(url, name):</div><div class="line">    &quot;&quot;&quot;</div><div class="line">    解析URL，返回HTML内容</div><div class="line">    :param url:解析的url</div><div class="line">    :param name: 保存的html文件名</div><div class="line">    :return: html</div><div class="line">    &quot;&quot;&quot;</div><div class="line">    try:</div><div class="line">        response = requests.get(url)</div><div class="line">        soup = BeautifulSoup(response.content, &apos;html.parser&apos;)</div><div class="line">        # 正文</div><div class="line">        body = soup.find_all(class_=&quot;x-wiki-content&quot;)[0]</div><div class="line">        # 标题</div><div class="line">        title = soup.find(&apos;h4&apos;).get_text()</div><div class="line">        # 标题加入到正文的最前面，居中显示</div><div class="line">        center_tag = soup.new_tag(&quot;center&quot;)</div><div class="line">        title_tag = soup.new_tag(&apos;h1&apos;)</div><div class="line">        title_tag.string = title</div><div class="line">        center_tag.insert(1, title_tag)</div><div class="line">        body.insert(1, center_tag)</div><div class="line">        html = str(body)</div><div class="line">        # body中的img标签的src相对路径的改成绝对路径</div><div class="line">        pattern = &quot;(&lt;img .*?src=\&quot;)(.*?)(\&quot;)&quot;</div><div class="line">        def func(m):</div><div class="line">            if not m.group(3).startswith(&quot;http&quot;):</div><div class="line">                rtn = m.group(1) + baseUrl + m.group(2) + m.group(3)</div><div class="line">                return rtn</div><div class="line">            else:</div><div class="line">                return m.group(1)+m.group(2)+m.group(3)</div><div class="line">        html = re.compile(pattern).sub(func, html)</div><div class="line">        html = html_template.format(content=html)</div><div class="line">        html = html.encode(&quot;utf-8&quot;)</div><div class="line">        with open(name, &apos;wb&apos;) as f:</div><div class="line">            f.write(html)</div><div class="line">        return name</div><div class="line">    except Exception as e:</div><div class="line">        logging.error(&quot;解析错误&quot;, exc_info=True)</div></pre></td></tr></table></figure>
<p>第二步就是把页面左侧所有 URL 解析出来。采用同样的方式，找到 左侧菜单标签<ul class="uk-nav uk-nav-side"></ul></p>
<p><img src="/2018/03/26/Python应用一将网页转换为pdf电子书/03.png" alt=""></p>
<p>具体代码实现逻辑：因为页面上有两个uk-nav uk-nav-side的 class 属性，而真正的目录列表是第二个。所有的 url 获取了，url 转 html 的函数在第一步也写好了。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div></pre></td><td class="code"><pre><div class="line">def get_url_list():</div><div class="line">    &quot;&quot;&quot;</div><div class="line">    获取所有URL目录列表</div><div class="line">    :return:</div><div class="line">    &quot;&quot;&quot;</div><div class="line">    response = requests.get(htmlUrl)</div><div class="line">    soup = BeautifulSoup(response.content, &quot;html.parser&quot;)</div><div class="line">    menu_tag = soup.find_all(class_=&quot;uk-nav uk-nav-side&quot;)[1]</div><div class="line">    urls = []</div><div class="line">    for li in menu_tag.find_all(&quot;li&quot;):</div><div class="line">        url = baseUrl + li.a.get(&apos;href&apos;)</div><div class="line">        urls.append(url)</div><div class="line">    return urls</div></pre></td></tr></table></figure>
<p>最后一步就是把 html 转换成pdf文件了。转换成 pdf 文件非常简单，因为 pdfkit 把所有的逻辑都封装好了，你只需要调用函数 pdfkit.from_file</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">def save_pdf(htmls, file_name):</div><div class="line">    &quot;&quot;&quot;</div><div class="line">    把所有html文件保存到pdf文件</div><div class="line">    :param htmls:  html文件列表</div><div class="line">    :param file_name: pdf文件名</div><div class="line">    :return:</div><div class="line">    &quot;&quot;&quot;</div><div class="line">    options = &#123;</div><div class="line">        &apos;page-size&apos;: &apos;Letter&apos;,</div><div class="line">        &apos;margin-top&apos;: &apos;0.75in&apos;,</div><div class="line">        &apos;margin-right&apos;: &apos;0.75in&apos;,</div><div class="line">        &apos;margin-bottom&apos;: &apos;0.75in&apos;,</div><div class="line">        &apos;margin-left&apos;: &apos;0.75in&apos;,</div><div class="line">        &apos;encoding&apos;: &quot;UTF-8&quot;,</div><div class="line">        &apos;custom-header&apos;: [</div><div class="line">            (&apos;Accept-Encoding&apos;, &apos;gzip&apos;)</div><div class="line">        ],</div><div class="line">        &apos;cookie&apos;: [</div><div class="line">            (&apos;cookie-name1&apos;, &apos;cookie-value1&apos;),</div><div class="line">            (&apos;cookie-name2&apos;, &apos;cookie-value2&apos;),</div><div class="line">        ],</div><div class="line">        &apos;outline-depth&apos;: 10,</div><div class="line">    &#125;</div><div class="line">    pdfkit.from_file(htmls, file_name, options=options)</div></pre></td></tr></table></figure>
<p>执行 save_pdf 函数，电子书 pdf 文件就生成了：</p>
<p>程序执行图</p>
<p><img src="/2018/03/26/Python应用一将网页转换为pdf电子书/04.png" alt=""></p>
<p>生成PDF文件</p>
<p><img src="/2018/03/26/Python应用一将网页转换为pdf电子书/05.png" alt=""></p>
<h2 id="点击下载源码"><a href="#点击下载源码" class="headerlink" title="点击下载源码"></a><a href="https://github.com/Henry519/PythonCrawler" target="_blank" rel="external">点击下载源码</a></h2>
  </section>

</article>
<section class="read-more">
           
    
               
            <div class="read-more-item">
                <span class="read-more-item-dim">最近的文章</span>
                <h2 class="post-list__post-title post-title"><a href="/2018/05/11/Python实践二数据分析/" title="Python实践二、数据分析">Python实践二、数据分析</a></h2>
                <p class="excerpt">
                
                写这篇文章的起因是我一个朋友的女友发表博士论文中要对采集的数据进行分析拟合，刚好这段时间工作不忙，在研究Python，所以就去折腾折腾。下面是两个需求：
12345需求一：根据公式计算MVD、MDNMND计算公式：[Σ(Bin Diameter*Num)]/ΣnumMVD计算公式：ΣVolum/Σn
                &hellip;
                </p>
                <div class="post-list__meta"><time datetime="2018-05-11T03:29:33.000Z" class="post-list__meta--date date">2018-05-11</time> &#8226; <span class="post-list__meta--tags tags">于&nbsp;
  <a class="tag-link" href="/tags/Python/">Python</a>
</span><a class="btn-border-small" href="/2018/05/11/Python实践二数据分析/">继续阅读</a></div>
                           
            </div>
        
        
               
            <div class="read-more-item">
                <span class="read-more-item-dim">更早的文章</span>
                <h2 class="post-list__post-title post-title"><a href="/2017/08/17/iOS开发-使用Cocoapods创建私有podspec/" title="iOS开发-使用Cocoapods创建私有podspec">iOS开发-使用Cocoapods创建私有podspec</a></h2>
                <p class="excerpt">
                
                Cocoapods是非常好用的一个iOS依赖管理工具，使用它可以方便的管理和更新项目中所使用到的第三方库，以及将自己的项目中的公共组件交由它去管理。制作共有podSpec可以参考我博客园里另一篇文章上传代码到cocoapod ,自己的框架提供给开发者使用。其实共有和私有的区别就在于对podSpec的
                &hellip;
                </p>
                <div class="post-list__meta"><time datetime="2017-08-17T02:43:27.000Z" class="post-list__meta--date date">2017-08-17</time> &#8226; <span class="post-list__meta--tags tags">于&nbsp;
  <a class="tag-link" href="/tags/iOS开发/">iOS开发</a>
</span><a class="btn-border-small" href="/2017/08/17/iOS开发-使用Cocoapods创建私有podspec/">继续阅读</a></div>
                       
            </div>
        
     
   
   
  
</section>

            
<section class="post-comments">
  <!-- 多说评论框 start -->
  <div class="ds-thread" data-thread-key="http://yoursite.com/2018/03/26/Python应用一将网页转换为pdf电子书/" data-title="Python实践一、将网页转换为pdf电子书" data-url="http://yoursite.com/2018/03/26/Python应用一将网页转换为pdf电子书/"></div>
  <!-- 多说评论框 end -->
  <!-- 多说公共JS代码 start (一个网页只需插入一次) -->
  <script type="text/javascript">
  var duoshuoQuery = {short_name:"tiantian419"};
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';ds.async = true;
    ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] 
     || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
  </script>
<!-- 多说公共JS代码 end -->
</section>


            <footer class="footer">
    <span class="footer__copyright">
        本站点采用 <a href="http://creativecommons.org/licenses/by-nc-sa/4.0/">知识共享署名-非商业性使用-相同方式共享 4.0 国际许可协议</a>
    </span>
    <span class="footer__copyright">
        基于 <a href="http://hexo.io">Hexo</a> 搭建，感谢 <a href="https://pages.github.com/">GitHub Pages</a> 提供免费的托管服务
    </span>
    <span class="footer__copyright">
        &copy; 2019 - 本站由 <a href="/">@Monniya</a> 创建,
        使用 <a href="https://github.com/monniya/hexo-theme-new-vno ">hexo-theme-new-vno</a> 主题,
        修改自 <a href="https://github.com/lenbo-ma/hexo-theme-vno" target="_blank">Vno</a>, 原创出自<a href="http://github.com/onevcat/vno" target="_blank">onevcat</a>
    </span>
</footer>
        </div>
    </div>

    

     
    
    <script>
        var _hmt = _hmt || [];
        (function() {
            var hm = document.createElement("script");
            hm.src = "//hm.baidu.com/hm.js?9cc5298dc110ef2815b741ef290dee21";
            var s = document.getElementsByTagName("script")[0]; 
            s.parentNode.insertBefore(hm, s);
        })();
    </script>



    <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js">
    
    </script>
    
</body>
</html>
